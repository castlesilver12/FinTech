{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Name: pima_indian_diabetes.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#EDA-chart / 수치화,결측처리-> corr()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#전처리 : outlier, scale(정규/표준), encoding\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, Binarizer #pd.get_dummpy()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.ensemble import Xg.. li...\n",
    "# from sklearn.metrics import mean_squared_error ... mse rmse mas rmsle\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myscore(y_test, pred, proba=None):\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    auc = roc_auc_score(y_test, proba[:,1].reshape(-1,1))\n",
    "    print(\"정확도:{:.4f},재현율:{:.4f},정밀도:{:.4f},f1:{:.4f},auc:{:.4f}\".format(accuracy,recall,precision,f1,auc))\n",
    "    print(\"confusion:\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./dataset/diabetes.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset/diabetes.csv\")\n",
    "y = df.iloc[:,-1]\n",
    "X = df.iloc[:,:-1]\n",
    "print(X.shape, y.shape)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============= 결측처리 / 숫자형 --> EDA\n",
    "df.hist(figsize=(6,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============= EDA(상관분석)\n",
    "sns.heatmap(df.corr(), cmap='Blues', annot=True, fmt='0.2f')\n",
    "plt.show()\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 타켓과 상관도가 높은 피쳐<br>\n",
    "'Outcome' : 'Glucose','BMI','Age'<br>\n",
    "* 다중공선x , 주요있게 살펴야할 피쳐<br>\n",
    "'Age' : 'Pregnancies'<br>\n",
    "'Insulin' : 'SkinThickness', 'Glucose'   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리 전 우선 점수부터 확인\n",
    "* 숫치형으로만 이루어진 데이터\n",
    "* 결측이 없는 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=160)\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict(X_test)\n",
    "proba = rf.predict_proba(X_test)\n",
    "print(\"전처리 전 우선 점수부터 확인------\\n\")\n",
    "myscore(y_test, pred, proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============= 전처리 : oulier 일환 = 0값 찾기\n",
    "features = X.columns\n",
    "for feature in features:\n",
    "    zero_cnt = X[X[feature]==0][feature].count()\n",
    "    print(feature, zero_cnt, zero_cnt/df.shape[0]*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_column = features[1:6]  #['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "print(zero_column)\n",
    "\n",
    "zero_column_mean = X[zero_column].mean().round(0)\n",
    "X[zero_column] = X[zero_column].replace(0, zero_column_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------ 0값 평균값으로 대체 : 변경확인 -----------\n",
    "for feature in X.columns:\n",
    "    zero_cnt = X[X[feature]==0][feature].count()\n",
    "    print(feature, zero_cnt, zero_cnt/X.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=160)\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict(X_test)\n",
    "proba = rf.predict_proba(X_test)\n",
    "print(\"평균값 채운 후 점수 확인------\\n\")\n",
    "myscore(y_test, pred, proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============= 정규화 : 평균0 분산1로 스케일 조정\n",
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit_transform(X)\n",
    "X_scaler_df = pd.DataFrame(X_scaler, columns=X.columns)\n",
    "X_scaler_df.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_scaler_df, y, test_size=0.2, random_state=160)\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict(X_test)\n",
    "proba = rf.predict_proba(X_test)\n",
    "print(pred[:10])  #당뇨인지 아닌지 내가 예측한거\n",
    "print(proba[:10])\n",
    "\n",
    "print(\"정규화 후 점수 확인------\\n\")\n",
    "myscore(y_test, pred, proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정밀도_재현율 커브 곡선 ( 임계치 확인용 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pscore,rscore,th = precision_recall_curve(y_test, proba[:,-1])\n",
    "print(len(pscore), len(rscore), len(th)) #58 58 57\n",
    "\n",
    "plt.plot(th, pscore[:len(th)], label=\"precision\")\n",
    "plt.plot(th, rscore[:len(th)], label=\"recall\")\n",
    "plt.xlabel(\"thredholds\")\n",
    "plt.ylabel(\"precision recall value\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.3,0.4,0.5,0.55, 0.6]\n",
    "for th in thresholds:\n",
    "    binarizer = Binarizer(threshold=th)\n",
    "    pred = binarizer.fit_transform(proba[:,-1].reshape(-1,1))\n",
    "    \n",
    "    print(\"Negative:Positive\",th,1-th)  #, pred[:10], proba[:10])#P.s\n",
    "    myscore(y_test, pred, proba)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### roc_curv() 커브 곡선 ( 임계치 확인용 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fpr,tpr,th = roc_curve(y_test, proba[:,-1]) #th: max(score_len) + 1\n",
    "plt.plot(fpr, tpr, label=\"roc\")\n",
    "plt.plot([0,1], [0,1], label=\"th:0.5\")\n",
    "plt.xlabel(\"FPR(1-sen.)\")\n",
    "plt.ylabel(\"TPR(recall)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = roc_auc_score(y_test, proba[:,-1].reshape(-1,1))\n",
    "print(\"AUC Score:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단일 모델 \n",
    "* 평가  / 검증 / 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* 5.2. KNN<br>\n",
    "n_neighbors: Number of neighbors to use by default for k_neighbors queries\n",
    "model_KNN = KNeighborsClassifier()\n",
    "neighbors = [1,2,3,4]\n",
    "param_grid = dict(n_neighbors=neighbors)\n",
    "<br>\n",
    "* 5.3. SVC<br>\n",
    "C: The Penalty parameter C of the error term.\n",
    "Kernel: Kernel type could be linear, poly, rbf or sigmoid.\n",
    "c_values = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.3, 1.5, 1.7, 2.0]\n",
    "kernel_values = [ 'linear' , 'poly' , 'rbf' , 'sigmoid' ]\n",
    "param_grid = dict(C=c_values, kernel=kernel_values)\n",
    "model_SVC = SVC()\n",
    "<br>\n",
    "* 5.4. Decision Tree<br>\n",
    "param_grid = dict(max_depth = 4, min_samples_leaf = 6,\n",
    "                  criterion = [\"gini\", \"entropy\"])\n",
    "model_CART = DecisionTreeClassifier()\n",
    " <br>\n",
    "* 5.5 AdaBoostClassifier <br>\n",
    "learning_rate: Learning rate shrinks the contribution of each classifier by learning_rate.\n",
    "n_estimators: Number of trees to build. <br>\n",
    "\n",
    "learning_rate_value = [.01,.05,.1,.5, 1]\n",
    "n_estimators_value = [50,100,150,200,250,300]\n",
    "\n",
    "model_Ad = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 5.1.Logistic Regression<br>\n",
    "C(L2 규제) 값이 클수록 규제강도가 커진다(오버피팅 피하기) <br>\n",
    "L2 - 릿지 - 왜곡,편중,이상치 데이터가 많은 경우 <br>\n",
    "L1 - 라쏘 - 불필요한 피쳐수를 줄이는 경우 <br>\n",
    "\n",
    "C : Regularization value, the more, the stronger the regularization(double).<br>\n",
    "RegularizationType: Can be either \"L2\" or “L1”. Default is “L2”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,X_test,y_train,y_test\n",
    "def fit_predict(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    proba = model.predict_proba(X_test)\n",
    "    myscore(y_test, pred, proba)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "penalty = ['l2']  #['l1', 'l2']\n",
    "C= [0.5, 1.0, 3.0]\n",
    "\n",
    "for p in penalty:\n",
    "    for c in C:\n",
    "        print(\"규제, 강도\", p, c)\n",
    "        model = LogisticRegression(random_state=11,penalty=p, C=c)\n",
    "        fit_predict(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 5.6 GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# cv=5\n",
    "learning_rate_value = [1.0]\n",
    "n_estimators_value = [100,300,500,600]\n",
    "# for c in cv:  #GridsearchCV와 다르다.(같은 데이터를 5번 학습)\n",
    "for lr in learning_rate_value:\n",
    "    for est in n_estimators_value:\n",
    "        print(\"lr, 트리갯수\", lr, est)\n",
    "        model = GradientBoostingClassifier(random_state=11,learning_rate=lr, n_estimators=est)\n",
    "        fit_predict(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 5.7 XGBoost, LightGBM, Nueal Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "n_estimators_value = [100,300,500]\n",
    "max_depth = [3,5,7]\n",
    "#과적합 :: min_child_weight(작게) / gamma(노드분기:크게)\n",
    "#         eta(learnrate:작게)\n",
    "for est in n_estimators_value:\n",
    "    for depth in max_depth:\n",
    "        print(\"트리갯수, 트리깊이\", est, depth)\n",
    "        model = XGBClassifier(objective=\"binary:logistic\",\n",
    "                            #early_stopping_rounds=10,\n",
    "                            eval_metric=\"auc\",\n",
    "                            n_estimators=est,\n",
    "                            max_depth = depth\n",
    "        )\n",
    "        fit_predict(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble : Voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# model1 = LogisticRegression()\n",
    "# model8 = RandomForestClassifier()\n",
    "\n",
    "model_1 = GradientBoostingClassifier(random_state=11,learning_rate=1.0, n_estimators=600)        \n",
    "model_2 = XGBClassifier(objective=\"binary:logistic\",\n",
    "                            #early_stopping_rounds=10,\n",
    "                            eval_metric=\"auc\",\n",
    "                            n_estimators=100,\n",
    "                            max_depth = 3\n",
    "        )\n",
    "\n",
    "model_list = [('GB',model_1), ('XGB',model_2)]\n",
    "ensemble_model = VotingClassifier(model_list, voting='soft')\n",
    "\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "pred = ensemble_model.predict(X_test)\n",
    "proba = ensemble_model.predict_proba(X_test)\n",
    "myscore(y_test, pred, proba)\n",
    "\n",
    "\n",
    "# score5 = cross_val_score(ensemble_model, X, y, cv=5)  #, scoring='f1')\n",
    "# print('평균정확도: ',score5.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_param = { \"n_estimators\":[5,10,50,100] #,200,300,400], \n",
    "                \"max_depth\":[3,4,5,6,7,8]}\n",
    "model = XGBClassifier(objective=\"binary:logistic\",\n",
    "                            #eval_metric=\"auc\",\n",
    "                            #n_estimators=est,\n",
    "                            #max_depth = depth\n",
    "        )\n",
    "grid_model = GridSearchCV(estimator=model,\n",
    "                          param_grid=hyper_param,\n",
    "             scoring='roc_auc',  refit=True, cv=5, verbose=0)\n",
    "grid_model.fit(X_train, y_train)\n",
    "print(grid_model.best_params_)\n",
    "print(grid_model.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
